{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Web Scraping Lab\n",
    "\n",
    "In this lab you will first learn the following code snippet which is a simple web spider class that allows you to scrape paginated webpages. Read the code, run it, and make sure you understand how it work. In the challenges of this lab, we will guide you in building up this class so that eventually you will have a more robus web spider that you can further work on in the Web Scraping Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scrape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    quotes=soup.select('span[itemprop~=\"text\"]')\n",
    "    return [i.text for i in quotes]\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1 - Custom Parser Function\n",
    "\n",
    "In this challenge, complete the custom `quotes_parser()` function so that the returned result contains the quote string instead of the whole html page content.\n",
    "\n",
    "In the cell below, write your updated `quotes_parser()` function and kickstart the spider. Make sure the results being printed contain a list of quote strings extracted from the html content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    quotes=soup.select('span[itemprop~=\"text\"]')\n",
    "    return [i.text for i in quotes]\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 - Error Handling\n",
    "\n",
    "In `IronhackSpider.scrape_url()`, catch any error that might occur when you make requests to scrape the webpage. This includes checking the response status code and catching http request errors such as timeout, SSL, and too many redirects.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request was successful\n",
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# Estuve manoseando esto con Felipe pero no me ha quedado muy claro. Agradecería que me dijeseis una forma buena \n",
    "#de hacer esto\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scrape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code < 300:\n",
    "                print('request was successful')\n",
    "            elif response.status_code >= 400 and response.status_code < 500:\n",
    "                print('request failed because the resource either does not exist or is forbidden')\n",
    "            else:\n",
    "                print('request failed because the response server encountered an error')\n",
    "        except requests.exceptions.Timeout:\n",
    "            pass\n",
    "            # timeout error...\n",
    "        except requests.exceptions.TooManyRedirects:\n",
    "            pass\n",
    "            # redirect error...\n",
    "        except requests.exceptions.SSLError:\n",
    "            pass\n",
    "            # ssl error...\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            pass\n",
    "            # other unknown errors...\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        for i in range(1, self.pages_to_scrape+1):\n",
    "            self.scrape_url(self.url_pattern % i)\n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    quotes=soup.select('span[itemprop=\"text\"]')\n",
    "    return [i.text for i in quotes]\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Sleep Interval\n",
    "\n",
    "In `IronhackSpider.kickstart()`, implement `sleep_interval`. You will check if `self.sleep_interval` is larger than 0. If so, tell the FOR loop to sleep the given amount of time before making the next request.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scrape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        if self.sleep_interval>0:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                time.sleep(self.sleep_interval)\n",
    "                self.scrape_url(self.url_pattern % i)\n",
    "        else:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                self.scrape_url(self.url_pattern % i)  \n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 1 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    quotes=soup.select('span[itemprop~=\"text\"]')\n",
    "    return [i.text for i in quotes]\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser,sleep_interval=3)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Test Batch Scraping\n",
    "\n",
    "Change the `PAGES_TO_SCRAPE` value from `1` to `10`. Try if your code still works as intended to scrape 10 webpages. If there are errors in your code, fix them.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n",
      "[\"“This life is what you make it. No matter what, you're going to mess up sometimes, it's a universal truth. But the good part is you get to decide how you're going to mess it up. Girls will be your friends - they'll act like it anyway. But just remember, some come, some go. The ones that stay with you through everything - they're your true best friends. Don't let go of them. Also remember, sisters make the best friends in the world. As for lovers, well, they'll come and go too. And baby, I hate to say it, most of them - actually pretty much all of them are going to break your heart, but you can't give up because if you give up, you'll never find your soulmate. You'll never find that half who makes you whole and that goes for everything. Just because you fail once, doesn't mean you're gonna fail at everything. Keep trying, hold on, and always, always, always believe in yourself, because if you don't, then who will, sweetie? So keep your head high, keep your chin up, and most importantly, keep smiling, because life's a beautiful thing and there's so much to smile about.”\", '“It takes a great deal of bravery to stand up to our enemies, but just as much to stand up to our friends.”', \"“If you can't explain it to a six year old, you don't understand it yourself.”\", \"“You may not be her first, her last, or her only. She loved before she may love again. But if she loves you now, what else matters? She's not perfect—you aren't either, and the two of you may never be perfect together but if she can make you laugh, cause you to think twice, and admit to being human and making mistakes, hold onto her and give her the most you can. She may not be thinking about you every second of the day, but she will give you a part of her that she knows you can break—her heart. So don't hurt her, don't change her, don't analyze and don't expect more than she can give. Smile when she makes you happy, let her know when she makes you mad, and miss her when she's not there.”\", '“I like nonsense, it wakes up the brain cells. Fantasy is a necessary ingredient in living.”', '“I may not have gone where I intended to go, but I think I have ended up where I needed to be.”', \"“The opposite of love is not hate, it's indifference. The opposite of art is not ugliness, it's indifference. The opposite of faith is not heresy, it's indifference. And the opposite of life is not death, it's indifference.”\", '“It is not a lack of love, but a lack of friendship that makes unhappy marriages.”', '“Good friends, good books, and a sleepy conscience: this is the ideal life.”', '“Life is what happens to us while we are making other plans.”']\n",
      "['“I love you without knowing how, or when, or from where. I love you simply, without problems or pride: I love you in this way because I do not know any other way of loving but this, in which there is no I or you, so intimate that your hand upon my chest is my hand, so intimate that when I fall asleep your eyes close.”', '“For every minute you are angry you lose sixty seconds of happiness.”', '“If you judge people, you have no time to love them.”', '“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”', '“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”', '“Today you are You, that is truer than true. There is no one alive who is Youer than You.”', '“If you want your children to be intelligent, read them fairy tales. If you want them to be more intelligent, read them more fairy tales.”', '“It is impossible to live without failing at something, unless you live so cautiously that you might as well not have lived at all - in which case, you fail by default.”', '“Logic will get you from A to Z; imagination will get you everywhere.”', '“One good thing about music, when it hits you, you feel no pain.”']\n",
      "[\"“The more that you read, the more things you will know. The more that you learn, the more places you'll go.”\", '“Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real?”', '“The truth is, everyone is going to hurt you. You just got to find the ones worth suffering for.”', '“Not all of us can do great things. But we can do small things with great love.”', '“To the well-organized mind, death is but the next great adventure.”', \"“All you need is love. But a little chocolate now and then doesn't hurt.”\", \"“We read to know we're not alone.”\", '“Any fool can know. The point is to understand.”', '“I have always imagined that Paradise will be a kind of library.”', '“It is never too late to be what you might have been.”']\n",
      "['“A reader lives a thousand lives before he dies, said Jojen. The man who never reads lives only one.”', '“You can never get a cup of tea large enough or a book long enough to suit me.”', '“You believe lies so you eventually learn to trust no one but yourself.”', '“If you can make a woman laugh, you can make her do anything.”', '“Life is like riding a bicycle. To keep your balance, you must keep moving.”', '“The real lover is the man who can thrill you by kissing your forehead or smiling into your eyes or just staring into space.”', \"“A wise girl kisses but doesn't love, listens but doesn't believe, and leaves before she is left.”\", '“Only in the darkness can you see the stars.”', '“It matters not what someone is born, but what they grow to be.”', '“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”']\n",
      "['“There is nothing I would not do for those who are really my friends. I have no notion of loving people by halves, it is not my nature.”', '“Do one thing every day that scares you.”', '“I am good, but not an angel. I do sin, but I am not the devil. I am just a small girl in a big world trying to find someone to love.”', '“If I were not a physicist, I would probably be a musician. I often think in music. I live my daydreams in music. I see my life in terms of music.”', '“If you only read the books that everyone else is reading, you can only think what everyone else is thinking.”', '“The difference between genius and stupidity is: genius has its limits.”', \"“He's like a drug for you, Bella.”\", '“There is no friend as loyal as a book.”', '“When one door of happiness closes, another opens; but often we look so long at the closed door that we do not see the one which has been opened for us.”', \"“Life isn't about finding yourself. Life is about creating yourself.”\"]\n",
      "[\"“That's the problem with drinking, I thought, as I poured myself a drink. If something bad happens you drink in an attempt to forget; if something good happens you drink in order to celebrate; and if nothing happens you drink to make something happen.”\", '“You don’t forget the face of the person who was your last hope.”', \"“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\", '“To love at all is to be vulnerable. Love anything and your heart will be wrung and possibly broken. If you want to make sure of keeping it intact you must give it to no one, not even an animal. Wrap it carefully round with hobbies and little luxuries; avoid all entanglements. Lock it up safe in the casket or coffin of your selfishness. But in that casket, safe, dark, motionless, airless, it will change. It will not be broken; it will become unbreakable, impenetrable, irredeemable. To love is to be vulnerable.”', '“Not all those who wander are lost.”', '“Do not pity the dead, Harry. Pity the living, and, above all those who live without love.”', '“There is nothing to writing. All you do is sit down at a typewriter and bleed.”', '“Finish each day and be done with it. You have done what you could. Some blunders and absurdities no doubt crept in; forget them as soon as you can. Tomorrow is a new day. You shall begin it serenely and with too high a spirit to be encumbered with your old nonsense.”', '“I have never let my schooling interfere with my education.”', \"“I have heard there are troubles of more than one kind. Some come from ahead and some come from behind. But I've bought a big bat. I'm all ready you see. Now my troubles are going to have troubles with me!”\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“If I had a flower for every time I thought of you...I could walk through my garden forever.”', '“Some people never go crazy. What truly horrible lives they must lead.”', '“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”', '“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”', \"“What really knocks me out is a book that, when you're all done reading it, you wish the author that wrote it was a terrific friend of yours and you could call him up on the phone whenever you felt like it. That doesn't happen much, though.”\", '“The reason I talk to myself is because I’m the only one whose answers I accept.”', \"“You may say I'm a dreamer, but I'm not the only one. I hope someday you'll join us. And the world will live as one.”\", '“I am free of all prejudice. I hate everyone equally. ”', \"“The question isn't who is going to let me; it's who is going to stop me.”\", \"“′Classic′ - a book which people praise and don't read.”\"]\n",
      "['“Anyone who has never made a mistake has never tried anything new.”', \"“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\", '“Remember, if the time should come when you have to make a choice between what is right and what is easy, remember what happened to a boy who was good, and kind, and brave, because he strayed across the path of Lord Voldemort. Remember Cedric Diggory.”', '“I declare after all there is no enjoyment like reading! How much sooner one tires of any thing than of a book! -- When I have a house of my own, I shall be miserable if I have not an excellent library.”', '“There are few people whom I really love, and still fewer of whom I think well. The more I see of the world, the more am I dissatisfied with it; and every day confirms my belief of the inconsistency of all human characters, and of the little dependence that can be placed on the appearance of merit or sense.”', '“Some day you will be old enough to start reading fairy tales again.”', '“We are not necessarily doubting that God will do the best for us; we are wondering how painful the best will turn out to be.”', '“The fear of death follows from the fear of life. A man who lives fully is prepared to die at any time.”', '“A lie can travel half way around the world while the truth is putting on its shoes.”', '“I believe in Christianity as I believe that the sun has risen: not only because I see it, but because by it I see everything else.”']\n",
      "['“The truth.\" Dumbledore sighed. \"It is a beautiful and terrible thing, and should therefore be treated with great caution.”', \"“I'm the one that's got to die when it's time for me to die, so let me live my life the way I want to.”\", '“To die will be an awfully big adventure.”', '“It takes courage to grow up and become who you really are.”', '“But better to get hurt by the truth than comforted with a lie.”', '“You never really understand a person until you consider things from his point of view... Until you climb inside of his skin and walk around in it.”', '“You have to write the book that wants to be written. And if the book will be too difficult for grown-ups, then you write it for children.”', '“Never tell the truth to people who are not worthy of it.”', \"“A person's a person, no matter how small.”\", '“... a mind needs books as a sword needs a whetstone, if it is to keep its edge.”']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scrape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        if self.sleep_interval>0:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                time.sleep(self.sleep_interval)\n",
    "                self.scrape_url(self.url_pattern % i)\n",
    "        else:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                self.scrape_url(self.url_pattern % i)  \n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://quotes.toscrape.com/page/%s/' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 10 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    quotes=soup.select('span[itemprop~=\"text\"]')\n",
    "    return [i.text for i in quotes]\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser,sleep_interval=-1)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Scrape a Different Website\n",
    "\n",
    "Update the parameters passed to the `IronhackSpider` constructor so that you coder can crawl [books.toscrape.com](http://books.toscrape.com/). You will need to use a different `URL_PATTERN` (figure out the new url pattern by yourself) and write another parser function to be passed to `IronhackSpider`. \n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"A Light in the Attic\"', '\"Tipping the Velvet\"', '\"Soumission\"', '\"Sharp Objects\"', '\"Sapiens: A Brief History of Humankind\"', '\"The Requiem Red\"', '\"The Dirty Little Secrets of Getting Your Dream Job\"', '\"The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\"', '\"The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\"', '\"The Black Maria\"', '\"Starving Hearts (Triangular Trade Trilogy, #1)\"', '\"Shakespeare\\'s Sonnets\"', '\"Set Me Free\"', '\"Scott Pilgrim\\'s Precious Little Life (Scott Pilgrim #1)\"', '\"Rip it Up and Start Again\"', '\"Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\"', '\"Olio\"', '\"Mesaerion: The Best Science Fiction Stories 1800-1849\"', '\"Libertarianism for Beginners\"', '\"It\\'s Only the Himalayas\"']\n",
      "['\"In Her Wake\"', '\"How Music Works\"', '\"Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More\"', '\"Chase Me (Paris Nights #2)\"', '\"Black Dust\"', '\"Birdsong: A Story in Pictures\"', '\"America\\'s Cradle of Quarterbacks: Western Pennsylvania\\'s Football Factory from Johnny Unitas to Joe Montana\"', '\"Aladdin and His Wonderful Lamp\"', '\"Worlds Elsewhere: Journeys Around Shakespeare’s Globe\"', '\"Wall and Piece\"', '\"The Four Agreements: A Practical Guide to Personal Freedom\"', '\"The Five Love Languages: How to Express Heartfelt Commitment to Your Mate\"', '\"The Elephant Tree\"', '\"The Bear and the Piano\"', '\"Sophie\\'s World\"', '\"Penny Maybe\"', '\"Maude (1883-1993):She Grew Up with the country\"', '\"In a Dark, Dark Wood\"', '\"Behind Closed Doors\"', '\"You can\\'t bury them all: Poems\"']\n",
      "['\"Slow States of Collapse: Poems\"', '\"Reasons to Stay Alive\"', '\"Private Paris (Private #10)\"', '\"#HigherSelfie: Wake Up Your Life. Free Your Soul. Find Your Tribe.\"', '\"Without Borders (Wanderlove #1)\"', '\"When We Collided\"', '\"We Love You, Charlie Freeman\"', '\"Untitled Collection: Sabbath Poems 2014\"', '\"Unseen City: The Majesty of Pigeons, the Discreet Charm of Snails &amp; Other Wonders of the Urban Wilderness\"', '\"Unicorn Tracks\"', '\"Unbound: How Eight Technologies Made Us Human, Transformed Society, and Brought Our World to the Brink\"', '\"Tsubasa: WoRLD CHRoNiCLE 2 (Tsubasa WoRLD CHRoNiCLE #2)\"', '\"Throwing Rocks at the Google Bus: How Growth Became the Enemy of Prosperity\"', '\"This One Summer\"', '\"Thirst\"', '\"The Torch Is Passed: A Harding Family Story\"', '\"The Secret of Dreadwillow Carse\"', '\"The Pioneer Woman Cooks: Dinnertime: Comfort Classics, Freezer Food, 16-Minute Meals, and Other Delicious Ways to Solve Supper!\"', '\"The Past Never Ends\"', '\"The Natural History of Us (The Fine Art of Pretending #2)\"']\n",
      "['\"The Nameless City (The Nameless City #1)\"', '\"The Murder That Never Was (Forensic Instincts #5)\"', '\"The Most Perfect Thing: Inside (and Outside) a Bird\\'s Egg\"', '\"The Mindfulness and Acceptance Workbook for Anxiety: A Guide to Breaking Free from Anxiety, Phobias, and Worry Using Acceptance and Commitment Therapy\"', '\"The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing\"', '\"The Inefficiency Assassin: Time Management Tactics for Working Smarter, Not Longer\"', '\"The Gutsy Girl: Escapades for Your Life of Epic Adventure\"', '\"The Electric Pencil: Drawings from Inside State Hospital No. 3\"', '\"The Death of Humanity: and the Case for Life\"', '\"The Bulletproof Diet: Lose up to a Pound a Day, Reclaim Energy and Focus, Upgrade Your Life\"', '\"The Art Forger\"', '\"The Age of Genius: The Seventeenth Century and the Birth of the Modern Mind\"', '\"The Activist\\'s Tao Te Ching: Ancient Advice for a Modern Revolution\"', '\"Spark Joy: An Illustrated Master Class on the Art of Organizing and Tidying Up\"', '\"Soul Reader\"', '\"Security\"', '\"Saga, Volume 6 (Saga (Collected Editions) #6)\"', '\"Saga, Volume 5 (Saga (Collected Editions) #5)\"', '\"Reskilling America: Learning to Labor in the Twenty-First Century\"', '\"Rat Queens, Vol. 3: Demons (Rat Queens (Collected Editions) #11-15)\"']\n",
      "['\"Princess Jellyfish 2-in-1 Omnibus, Vol. 01 (Princess Jellyfish 2-in-1 Omnibus #1)\"', '\"Princess Between Worlds (Wide-Awake Princess #5)\"', '\"Pop Gun War, Volume 1: Gift\"', '\"Political Suicide: Missteps, Peccadilloes, Bad Calls, Backroom Hijinx, Sordid Pasts, Rotten Breaks, and Just Plain Dumb Mistakes in the Annals of American Politics\"', '\"Patience\"', '\"Outcast, Vol. 1: A Darkness Surrounds Him (Outcast #1)\"', '\"orange: The Complete Collection 1 (orange: The Complete Collection #1)\"', '\"Online Marketing for Busy Authors: A Step-By-Step Guide\"', '\"On a Midnight Clear\"', '\"Obsidian (Lux #1)\"', '\"My Paris Kitchen: Recipes and Stories\"', '\"Masks and Shadows\"', '\"Mama Tried: Traditional Italian Cooking for the Screwed, Crude, Vegan, and Tattooed\"', '\"Lumberjanes, Vol. 2: Friendship to the Max (Lumberjanes #5-8)\"', '\"Lumberjanes, Vol. 1: Beware the Kitten Holy (Lumberjanes #1-4)\"', '\"Lumberjanes Vol. 3: A Terrible Plan (Lumberjanes #9-12)\"', '\"Layered: Baking, Building, and Styling Spectacular Cakes\"', '\"Judo: Seven Steps to Black Belt (an Introductory Guide for Beginners)\"', '\"Join\"', '\"In the Country We Love: My Family Divided\"']\n",
      "['\"Immunity: How Elie Metchnikoff Changed the Course of Modern Medicine\"', '\"I Hate Fairyland, Vol. 1: Madly Ever After (I Hate Fairyland (Compilations) #1-5)\"', '\"I am a Hero Omnibus Volume 1\"', '\"How to Be Miserable: 40 Strategies You Already Use\"', '\"Her Backup Boyfriend (The Sorensen Family #1)\"', '\"Giant Days, Vol. 2 (Giant Days #5-8)\"', '\"Forever and Forever: The Courtship of Henry Longfellow and Fanny Appleton\"', '\"First and First (Five Boroughs #3)\"', '\"Fifty Shades Darker (Fifty Shades #2)\"', '\"Everydata: The Misinformation Hidden in the Little Data You Consume Every Day\"', '\"Don\\'t Be a Jerk: And Other Practical Advice from Dogen, Japan\\'s Greatest Zen Master\"', '\"Danganronpa Volume 1\"', '\"Crown of Midnight (Throne of Glass #2)\"', '\"Codename Baboushka, Volume 1: The Conclave of Death\"', '\"Camp Midnight\"', '\"Call the Nurse: True Stories of a Country Nurse on a Scottish Isle\"', '\"Burning\"', '\"Bossypants\"', '\"Bitch Planet, Vol. 1: Extraordinary Machine (Bitch Planet (Collected Editions))\"', '\"Avatar: The Last Airbender: Smoke and Shadow, Part 3 (Smoke and Shadow #3)\"']\n",
      "['\"Algorithms to Live By: The Computer Science of Human Decisions\"', '\"A World of Flavor: Your Gluten Free Passport\"', '\"A Piece of Sky, a Grain of Rice: A Memoir in Four Meditations\"', '\"A Murder in Time\"', '\"A Flight of Arrows (The Pathfinders #2)\"', '\"A Fierce and Subtle Poison\"', '\"A Court of Thorns and Roses (A Court of Thorns and Roses #1)\"', '\"(Un)Qualified: How God Uses Broken People to Do Big Things\"', '\"You Are What You Love: The Spiritual Power of Habit\"', '\"William Shakespeare\\'s Star Wars: Verily, A New Hope (William Shakespeare\\'s Star Wars #4)\"', '\"Tuesday Nights in 1980\"', '\"Tracing Numbers on a Train\"', '\"Throne of Glass (Throne of Glass #1)\"', '\"Thomas Jefferson and the Tripoli Pirates: The Forgotten War That Changed American History\"', '\"Thirteen Reasons Why\"', '\"The White Cat and the Monk: A Retelling of the Poem “Pangur Bán”\"', '\"The Wedding Dress\"', '\"The Vacationers\"', '\"The Third Wave: An Entrepreneur’s Vision of the Future\"', '\"The Stranger\"']\n",
      "['\"The Shadow Hero (The Shadow Hero)\"', '\"The Secret (The Secret #1)\"', '\"The Regional Office Is Under Attack!\"', '\"The Psychopath Test: A Journey Through the Madness Industry\"', '\"The Project\"', '\"The Power of Now: A Guide to Spiritual Enlightenment\"', '\"The Omnivore\\'s Dilemma: A Natural History of Four Meals\"', '\"The Nerdy Nummies Cookbook: Sweet Treats for the Geek in All of Us\"', '\"The Murder of Roger Ackroyd (Hercule Poirot #4)\"', '\"The Mistake (Off-Campus #2)\"', '\"The Matchmaker\\'s Playbook (Wingmen Inc. #1)\"', '\"The Love and Lemons Cookbook: An Apple-to-Zucchini Celebration of Impromptu Cooking\"', '\"The Long Shadow of Small Ghosts: Murder and Memory in an American City\"', '\"The Kite Runner\"', '\"The House by the Lake\"', '\"The Glittering Court (The Glittering Court #1)\"', '\"The Girl on the Train\"', '\"The Genius of Birds\"', '\"The Emerald Mystery\"', '\"The Cookies &amp; Cups Cookbook: 125+ sweet &amp; savory recipes reminding you to Always Eat Dessert First\"']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"The Bridge to Consciousness: I\\'m Writing the Bridge Between Science and Our Old and New Beliefs.\"', '\"The Artist\\'s Way: A Spiritual Path to Higher Creativity\"', '\"The Art of War\"', '\"The Argonauts\"', '\"The 10% Entrepreneur: Live Your Startup Dream Without Quitting Your Day Job\"', '\"Suddenly in Love (Lake Haven #1)\"', '\"Something More Than This\"', '\"Soft Apocalypse\"', '\"So You\\'ve Been Publicly Shamed\"', '\"Shoe Dog: A Memoir by the Creator of NIKE\"', '\"Shobu Samurai, Project Aryoku (#3)\"', '\"Secrets and Lace (Fatal Hearts #1)\"', '\"Scarlett Epstein Hates It Here\"', '\"Romero and Juliet: A Tragic Tale of Love and Zombies\"', '\"Redeeming Love\"', '\"Poses for Artists Volume 1 - Dynamic and Sitting Poses: An Essential Reference for Figure Drawing and the Human Form\"', '\"Poems That Make Grown Women Cry\"', '\"Nightingale, Sing\"', '\"Night Sky with Exit Wounds\"', '\"Mrs. Houdini\"']\n",
      "['\"Modern Romance\"', '\"Miss Peregrine’s Home for Peculiar Children (Miss Peregrine’s Peculiar Children #1)\"', '\"Louisa: The Extraordinary Life of Mrs. Adams\"', '\"Little Red\"', '\"Library of Souls (Miss Peregrine’s Peculiar Children #3)\"', '\"Large Print Heart of the Pride\"', '\"I Had a Nice Time And Other Lies...: How to find love &amp; sh*t like that\"', '\"Hollow City (Miss Peregrine’s Peculiar Children #2)\"', '\"Grumbles\"', '\"Full Moon over Noah’s Ark: An Odyssey to Mount Ararat and Beyond\"', '\"Frostbite (Vampire Academy #2)\"', '\"Follow You Home\"', '\"First Steps for New Christians (Print Edition)\"', '\"Finders Keepers (Bill Hodges Trilogy #2)\"', '\"Fables, Vol. 1: Legends in Exile (Fables #1)\"', '\"Eureka Trivia 6.0\"', '\"Drive: The Surprising Truth About What Motivates Us\"', '\"Done Rubbed Out (Reightman &amp; Bailey #1)\"', '\"Doing It Over (Most Likely To #1)\"', '\"Deliciously Ella Every Day: Quick and Easy Recipes for Gluten-Free Snacks, Packed Lunches, and Simple Meals\"']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "# your code here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "class IronhackSpider:\n",
    "    \"\"\"\n",
    "    This is the constructor class to which you can pass a bunch of parameters. \n",
    "    These parameters are stored to the class instance variables so that the\n",
    "    class functions can access them later.\n",
    "    \n",
    "    url_pattern: the regex pattern of the web urls to scrape\n",
    "    pages_to_scrape: how many pages to scrape\n",
    "    sleep_interval: the time interval in seconds to delay between requests. If <0, requests will not be delayed.\n",
    "    content_parser: a function reference that will extract the intended info from the scraped content.\n",
    "    \"\"\"\n",
    "    def __init__(self, url_pattern, pages_to_scrape=10, sleep_interval=-1, content_parser=None):\n",
    "        self.url_pattern = url_pattern\n",
    "        self.pages_to_scrape = pages_to_scrape\n",
    "        self.sleep_interval = sleep_interval\n",
    "        self.content_parser = content_parser\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrape the content of a single url.\n",
    "    \"\"\"\n",
    "    def scrape_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        result = self.content_parser(response.content)\n",
    "        self.output_results(result)\n",
    "    \n",
    "    \"\"\"\n",
    "    Export the scraped content. Right now it simply print out the results.\n",
    "    But in the future you can export the results into a text file or database.\n",
    "    \"\"\"\n",
    "    def output_results(self, r):\n",
    "        print(r)\n",
    "    \n",
    "    \"\"\"\n",
    "    After the class is instantiated, call this function to start the scraping jobs.\n",
    "    This function uses a FOR loop to call `scrape_url()` for each url to scrape.\n",
    "    \"\"\"\n",
    "    def kickstart(self):\n",
    "        if self.sleep_interval>0:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                time.sleep(self.sleep_interval)\n",
    "                self.scrape_url(self.url_pattern % i)\n",
    "        else:\n",
    "            for i in range(1, self.pages_to_scrape+1):\n",
    "                self.scrape_url(self.url_pattern % i)  \n",
    "\n",
    "\n",
    "URL_PATTERN = 'http://books.toscrape.com/catalogue/page-%s.html' # regex pattern for the urls to scrape\n",
    "PAGES_TO_SCRAPE = 10 # how many webpages to scrapge\n",
    "\n",
    "\"\"\"\n",
    "This is a custom parser function you will complete in the challenge.\n",
    "Right now it simply returns the string passed to it. But in this lab\n",
    "you will complete this function so that it extracts the quotes.\n",
    "This function will be passed to the IronhackSpider class.\n",
    "\"\"\"\n",
    "def quotes_parser(content):\n",
    "    soup=BeautifulSoup(content)\n",
    "    books=soup.select('h3 a[title]')\n",
    "    retorno=[]\n",
    "    try:\n",
    "        for e in books:\n",
    "            w=str(e).split('title=')[1].split('>')[0]\n",
    "            retorno.append(w)\n",
    "        return retorno\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Instantiate the IronhackSpider class\n",
    "my_spider = IronhackSpider(URL_PATTERN, PAGES_TO_SCRAPE, content_parser=quotes_parser,sleep_interval=-1)\n",
    "\n",
    "# Start scraping jobs\n",
    "my_spider.kickstart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Making Your Spider Unblockable\n",
    "\n",
    "Use techniques such as randomizing user agents and referers in your requests to reduce the likelihood that your spider is blocked by websites. [Here](http://blog.adnansiddiqi.me/5-strategies-to-write-unblock-able-web-scrapers-in-python/) is a great article to learn these techniques.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Making Asynchronous Calls\n",
    "\n",
    "Implement asynchronous calls to `IronhackSpider`. You will make requests in parallel to complete your tasks faster.\n",
    "\n",
    "In the cell below, place your entire code including the updated `IronhackSpdier` class and the code to kickstart the spider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
